{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to deploy the backbreak's prediction web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.data.tabular_dataset import TabularDataset\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 0 to 24999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Impulse (I)                      25000 non-null  float64\n",
      " 1   Air density (pa)                 25000 non-null  float64\n",
      " 2   Positive Phase Duration (tp)     25000 non-null  float64\n",
      " 3   Peak Overpressure (pa)           25000 non-null  float64\n",
      " 4   Spacing (m)                      25000 non-null  float64\n",
      " 5   Stemming (m^3)                   25000 non-null  float64\n",
      " 6   Number of rows (explosive load)  25000 non-null  float64\n",
      " 7   Air-overpressure (index)         25000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('AIR_DEF.csv')\n",
    "df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "\n",
    "X_df = df.drop('Percentil_Rango', axis=1)\n",
    "y_df = df['Percentil_Rango']\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sklearn_GB_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(learning_rate=0.1, n_estimators=20, min_samples_split=15).fit(X_df,y_df)\n",
    "joblib.dump(model, 'sklearn_GB_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'C:/Users/alexm/AppData/Local/Temp/tmpadfryv2e' to 'managed-dataset/e7e3e12b-e9b4-45ca-8e2c-66d60604f735/'\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n",
      "Air dataset v1 (ID: f11f2086-e9dd-48d3-905f-86764c30811e)\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# The default datastore is a blob storage container where datasets are stored\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# Register the dataset\n",
    "ds = Dataset.Tabular.register_pandas_dataframe(\n",
    "        dataframe=df, \n",
    "        name='Air dataset', \n",
    "        description='Air-Overpresure',\n",
    "        target=datastore\n",
    "    )\n",
    "\n",
    "X = ds.drop_columns(\"Percentil_Rango\")\n",
    "y = ds.keep_columns(\"Percentil_Rango\")\n",
    "\n",
    "# Display information about the dataset\n",
    "print(ds.name + \" v\" + str(ds.version) + ' (ID: ' + ds.id + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model GB-model\n",
      "Name: GB-model\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name='GB-model',                # Name of the registered model in your workspace.\n",
    "                       model_path='./sklearn_GB_model.pkl',  # Local file to upload and register as a model.\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
    "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
    "                       sample_input_dataset=X,\n",
    "                       sample_output_dataset=y,\n",
    "                       resource_configuration=ResourceConfiguration(cpu=2, memory_in_gb=4),\n",
    "                       description='Gradient Boosting clasification model to predict air-overpressure.',\n",
    "                       tags={'area': 'air-overpressure', 'type': 'clasification'})\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Impulse (I)', 'Air density (pa)', 'Positive Phase Duration (tp)',\n",
       "       'Peak Overpressure (pa)', 'Spacing (m)', 'Stemming (m^3)',\n",
       "       'Number of rows (explosive load)', 'Air-overpressure (index)',\n",
       "       'Percentil_Rango'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score_air.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_air.py\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # Replace filename if needed.\n",
    "    path = os.getenv('AZUREML_MODEL_DIR') \n",
    "    model_path = os.path.join(path, 'sklearn_GB_model.pkl')\n",
    "    # Deserialize the model file back into a sklearn model.\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\n",
    "    \"Impulse (I)\": 3.61,\n",
    "    \"Air density (pa)\": 6.75,\n",
    "    \"Positive Phase Duration (tp)\": 2.78,\n",
    "    \"Peak Overpressure (pa)\": 6.23,\n",
    "    \"Spacing (m)\": 1.92,\n",
    "    \"Stemming (m^3)\": 4.21,\n",
    "    \"Number of rows (explosive load)\": 5.12,\n",
    "    \"Air-overpressure (index)\": 4.85,\n",
    "}])\n",
    "\n",
    "# This is an integer type sample. Use the data type that reflects the expected result.\n",
    "output_sample = np.array([0])\n",
    "\n",
    "# To indicate that we support a variable length of data input,\n",
    "# set enforce_shape=False\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        print(\"input_data....\")\n",
    "        print(data.columns)\n",
    "        print(type(data))\n",
    "        result = model.predict(data)\n",
    "        print(\"result.....\")\n",
    "        print(result)\n",
    "    # You can return any data type, as long as it can be serialized by JSON.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "environment = Environment('my-sklearn-environment')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'scikit-learn=={}'.format(sklearn.__version__)\n",
    "])\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='./score_air.py',environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-b6d1165b356d>:7: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(ws, service_name, [model], inference_config, deployment_config=aci_config, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-12-09 20:12:20+01:00 Creating Container Registry if not exists.\n",
      "2023-12-09 20:12:20+01:00 Registering the environment.\n",
      "2023-12-09 20:12:23+01:00 Use the existing image.\n",
      "2023-12-09 20:12:23+01:00 Generating deployment configuration.\n",
      "2023-12-09 20:12:24+01:00 Submitting deployment to compute.\n",
      "2023-12-09 20:12:27+01:00 Checking the status of deployment my-air-model..\n",
      "2023-12-09 20:13:49+01:00 Checking the status of inference endpoint my-air-model.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                memory_gb = 1,\n",
    "                                                auth_enabled=True)\n",
    "                                        \n",
    "service_name = 'my-air-model'\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config=aci_config, overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://eb43ed3f-7ca1-4be9-9e49-d08f52425abf.francecentral.azurecontainer.io/score\n",
      "http://eb43ed3f-7ca1-4be9-9e49-d08f52425abf.francecentral.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2xhqZi2C3ht0qSdeYwph4NTCCiUziBx\n"
     ]
    }
   ],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
