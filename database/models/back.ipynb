{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to deploy the backbreak's predictions as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.data.tabular_dataset import TabularDataset\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 0 to 24999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Burden (t)                       25000 non-null  float64\n",
      " 1   Hole diameter (m)                25000 non-null  float64\n",
      " 2   Spacing (m)                      25000 non-null  float64\n",
      " 3   Stemming (m^3)                   25000 non-null  float64\n",
      " 4   Hole depth (m)                   25000 non-null  float64\n",
      " 5   Specific charge (t)              25000 non-null  float64\n",
      " 6   Number of rows (explosive load)  25000 non-null  float64\n",
      " 7   Backbreak (index)                25000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('BACK_DEF.csv')\n",
    "df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "\n",
    "X_df = df.drop('Percentil_Rango', axis=1)\n",
    "y_df = df['Percentil_Rango']\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sklearn_RF_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=80, min_samples_split=0.5, min_samples_leaf=1).fit(X_df,y_df)\n",
    "joblib.dump(model,'sklearn_RF_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from 'C:/Users/alexm/AppData/Local/Temp/tmpe44t3c07' to 'managed-dataset/1ce00887-6c6a-471c-83e7-e8539587caa6/'\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n",
      "Backbreak dataset v10 (ID: a0b0a5f6-4799-4964-81f1-8b32123e004d)\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# The default datastore is a blob storage container where datasets are stored\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# Register the dataset\n",
    "ds = Dataset.Tabular.register_pandas_dataframe(\n",
    "        dataframe=df, \n",
    "        name='Backbreak dataset', \n",
    "        description='Backbreak',\n",
    "        target=datastore\n",
    "    )\n",
    "\n",
    "X = ds.drop_columns(\"Percentil_Rango\")\n",
    "y = ds.keep_columns(\"Percentil_Rango\")\n",
    "\n",
    "# Display information about the dataset\n",
    "print(ds.name + \" v\" + str(ds.version) + ' (ID: ' + ds.id + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model RF-model\n",
      "Name: RF-model\n",
      "Version: 6\n"
     ]
    }
   ],
   "source": [
    "# Registering model\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_name='RF-model',                # Name of the registered model in your workspace.\n",
    "                       model_path='./sklearn_RF_model.pkl',  # Local file to upload and register as a model.\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
    "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
    "                       sample_input_dataset=X,\n",
    "                       sample_output_dataset=y,\n",
    "                       resource_configuration=ResourceConfiguration(cpu=2, memory_in_gb=4),\n",
    "                       description='RF clasification model to predict backbreak.',\n",
    "                       tags={'area': 'backbreak', 'type': 'clasification'})\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score_back.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_back.py\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # Replace filename if needed.\n",
    "    path = os.getenv('AZUREML_MODEL_DIR') \n",
    "    model_path = os.path.join(path, 'sklearn_RF_model.pkl')\n",
    "    # Deserialize the model file back into a sklearn model.\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\n",
    "    \"Burden (t)\": 5.62,\n",
    "    \"Hole diameter (m)\": 6.74,\n",
    "    \"Spacing (m)\": 6.54,\n",
    "    \"Stemming (m^3)\": 2.75,\n",
    "    \"Hole depth (m)\": 9.3,\n",
    "    \"Specific charge (t)\": 0.42,\n",
    "    \"Number of rows (explosive load)\": 5.12,\n",
    "    \"Backbreak (index)\": 4.73,\n",
    "}])\n",
    "\n",
    "# This is an integer type sample. Use the data type that reflects the expected result.\n",
    "output_sample = np.array([0])\n",
    "\n",
    "# To indicate that we support a variable length of data input,\n",
    "# set enforce_shape=False\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        print(\"input_data....\")\n",
    "        print(data.columns)\n",
    "        print(type(data))\n",
    "        result = model.predict(data)\n",
    "        print(\"result.....\")\n",
    "        print(result)\n",
    "    # You can return any data type, as long as it can be serialized by JSON.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "environment = Environment('my-sklearn-environment')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'scikit-learn=={}'.format(sklearn.__version__)\n",
    "])\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='./score_back.py',environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-2fe35c568120>:7: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(ws, service_name, [model], inference_config, deployment_config=aci_config, overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2023-12-10 19:41:28+01:00 Creating Container Registry if not exists.\n",
      "2023-12-10 19:41:28+01:00 Registering the environment.\n",
      "2023-12-10 19:41:30+01:00 Use the existing image.\n",
      "2023-12-10 19:41:30+01:00 Generating deployment configuration.\n",
      "2023-12-10 19:41:30+01:00 Submitting deployment to compute.\n",
      "2023-12-10 19:41:32+01:00 Checking the status of deployment my-backbreak-model..\n",
      "2023-12-10 19:44:04+01:00 Checking the status of inference endpoint my-backbreak-model.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Deploying the service\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                memory_gb = 1,\n",
    "                                                auth_enabled=True)\n",
    "\n",
    "service_name = 'my-backbreak-model'\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config=aci_config, overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5-10%', '0-5%']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': X_df[0:2].values.tolist()\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://82dc32d0-e323-4cf6-ae96-b32b892c9e2b.francecentral.azurecontainer.io/score\n",
      "http://82dc32d0-e323-4cf6-ae96-b32b892c9e2b.francecentral.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tlj5Tar7gPGdBpVM6rX8p6eNHZdQqfzG\n"
     ]
    }
   ],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"85-90%\"]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service\n",
    "scoring_uri = 'http://82dc32d0-e323-4cf6-ae96-b32b892c9e2b.francecentral.azurecontainer.io/score'\n",
    "# If the service is authenticated, set the key or token\n",
    "key = 'Tlj5Tar7gPGdBpVM6rX8p6eNHZdQqfzG'\n",
    "\n",
    "set2 = [\n",
    "                5.313270987393447,\n",
    "                7.541981086635956,\n",
    "                9.702078178995714,\n",
    "                4.182776584238159,\n",
    "                9.354004597971354,\n",
    "                0.407808473556946,\n",
    "                5.619456740301016,\n",
    "                4.934506657692589]\n",
    " \n",
    "# Two sets of data to score, so we get two results back\n",
    "data = {\"data\": [set2]}\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
